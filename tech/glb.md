# 异地多活

- 异地：地理位置不同
- 多活：不同地理位置上的系统，都能提供业务服务
   - 无论访问哪个地区的服务，都能得到正确的业务服务
   - 某地区服务异常，用户可以访问其他地区服务得到正确的业务服务
- 容错
   - 可预期的错误
   - 冗余

## 到底解决什么问题

都是极端的场景
- 机房not available
- 城市not available
- 国家not available
- 地球not available?

## 引发异地多活思考的背景

2018年9月份云栖大会上蚂蚁金服当场把杭州的2个IDC的网线剪短...

### Buzz Words

- 单元化 Set
   - 一个单元可以包含多个IDC，但通常对应一个IDC
   - 纯粹的单元化解决的是：就近访问的问题
   - 相关技术：流量调度/session sticky/AB test user
   - 加上数据同步技术，就形成了异地多活
- 就近访问
- 异地多活
   - 数据同步是异地多活的基础
   - DB/Cache/MQ

### 容灾级别

```
node -> rack -> IDC -> city -> country -> planet?
```

- 单节点容灾
   - app/db/cache/mq broker
   - 都是各个系统的HA设计实现的：design for failure
- rack容灾
   - 故障类型：交换机故障/电源/物理损坏/人为操作失误(google的电源线颜色区分案例)
   - 交换机容错、电源容错可以解决
- 机房容灾
   - 故障类型：机房火灾/水灾/停电/楼宇坍塌/空调故障/光缆切断
   - 机房容错：火灾防范，多电源，多数据线路，UPS，发动机，与加油站的距离
   - 光缆切断，可以通过额外增加线路解决
   - 2个IDC并不具备机房容灾能力，至少需要3个IDC，因为zk/redis/etcd/consul等需要quorum
   - 部署3个节点，但只有2个IDC，那么节点分布必然(2, 1)，当2的IDC挂了，则剩下的节点/IDC无法形成quorum，无法正常工作
   - 3个IDC，每个IDC部署一个节点，那么一个IDC挂了还剩2节点，这就是“2地3中心”
- 城市容灾
   - 故障类型：地震/水灾/城市大停电/战争/政治隔离(新疆)
   - 3地5中心(OceanBase)
      - 3个城市拥有IDC(2, 2, 1)
      - 1个城市发生灾难，其他2个城市至少保证3个IDC存活，可以形成quorum
- 国家故障
   - Spanner

### 部署结构

- 同城异区(N AZ within a Region)
   - 延迟低，网络好，几乎与同IDC体验一样
   - 异区IDC之间通过专线连接，距离100KM-
   - RTT可以几乎与同一个机房相同
      - 降低系统复杂度
   - nasdaq的方案
   - 无法解决极端的城市容灾问题
- 跨城异地
   - 网络环境差(RTT高，丢包率是不能回避的问题)
   - 城市间距离要足够长(例如：北京/广州)
      - 否则解决不了地震问题
   - 无法解决强一致性要求数据的场景(存款余额)
      - 用户登录(不一致，那就重新登录)
      - content based site
      - twitter(即使丢失twitter/comments影响也不大，用户可能觉察不出来)
- 跨国异地
   - RTT极高，丢包率极高
   - aws
      - 亚洲账户是无法登录美国的
   - google
      - readonly scenario
      - 无论在哪个国家搜索，结果基本相同

### Hard to solve problems

- 强一致要求的数据
   - 存款余额(无法异地多活)
   - bj(A)转账给hz(B) $100
   - 库存，订单状态
- unique constraint
   - 账号注册，unique(name)，site(A) crash before rep to B; 用户被切换到site(B)，注册成功，但等site(A) recovers，唯一约束破坏
   
## Tricks

- 无需保证业务100%可用
   - 转账业务
      - “实时转账”变为“转账申请”，异步处理
      - 强一致问题变为最终一致
      - bj转账给sh，异步后，如果发现sh不可用，就等待retry
      - 牺牲的用户体验，可用通过如下方式弥补：事后发代金券，贴心的提示语
- 多种手段同步数据
   - MQ
   - 回源读取
   - 存储系统同步
- 只保证大多数用户的多活

### 误区

- 要保证所有业务都异地多活
   - 优先实现核心业务的异地多活
      - 但核心业务依赖非核心业务，怎么办?
- 要保证所有数据实时同步
   - 物理上的限制，不可能所有数据都实时同步
   - 必须尽量减少数据同步
      - 登录的token/session，就没必要同步：大不了让用户重新登录

## TODO

- how aws solve HA accross regions
- 能提供保险/再保险，来解决技术架构问题吗

